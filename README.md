
# üß† RAG Java Microservice

This project is a **Java 24 Spring AI RAG service** that integrates with **Ollama** for LLMs and **ChromaDB** for vector storage.  
It supports:
- **Multi-query retrieval**
- **Chat memory**
- **Requirements Analyst ‚Üí Doc Writer agent workflow**
- **Confluence-ready document generation**

---

## üöÄ Getting Started

### 1. Clone the repo
```bash
git clone https://github.com/akrios-d/rag-java-microservice.git
cd rag-java-microservice
```

### 2. Build & Run with Docker Compose
```bash
docker compose up --build
```

This will start:
- `rag-service` ‚Üí Spring Boot app (port **8081**)  
- `ollama` ‚Üí LLM backend (port **11434**)  
- `chroma` ‚Üí Vector database (port **8000**)  

---

## üîç Verify Services

- RAG API ‚Üí [http://localhost:8081/query](http://localhost:8081/query)  
- Ollama health ‚Üí [http://localhost:11434/api/tags](http://localhost:11434/api/tags)  
- Chroma API ‚Üí [http://localhost:8000/api/v1/heartbeat](http://localhost:8000/api/v1/heartbeat)  

---

## üì° Example Usage

### Ask a question
```bash
curl -X POST "http://localhost:8081/query?userId=test&multiQuery=true"      -H "Content-Type: application/json"      -d '{"question":"What is retrieval augmented generation?"}'
```

### Requirements Analyst Mode
```bash
curl -X POST "http://localhost:8081/requirements?userId=test"      -H "Content-Type: application/json"      -d '{"input":"I need a system for handling support tickets"}'
```

Once you type `generate`, the system switches to **Doc Writer** and produces a Confluence-ready document.

---

## ‚ö° Models

Pull the embedding model before running queries:
```bash
docker exec -it ollama ollama pull all-minilm
```

And optionally pull LLMs:
```bash
docker exec -it ollama ollama pull llama3.2
```

Chroma Locally
```bash
docker run -it --rm --name chroma -p 8000:8000 ghcr.io/chroma-core/chroma:1.0.0
```

---

## üîí Security Notes
- Runs as **non-root** (distroless base image).  
- Minimal runtime environment (no shell, no package manager).  
- Data for Ollama and Chroma is persisted in **Docker volumes**.  

---

## üõ† Development
Rebuild after changes:
```bash
docker compose up --build rag-service
```



